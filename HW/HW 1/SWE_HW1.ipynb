{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Software Engineering Homework 1: Testing 3 small LMs with different parameters"
      ],
      "metadata": {
        "id": "Z8Lc-V4oKsCg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "41lfYwQHKij6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aaa30de-9df2-40c8-bd20-15b27957d4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Model: EleutherAI/gpt-neo-125M\n",
            "\n",
            "----\n",
            "Params: {'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'repetition_penalty': 1.5}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: Today I learned how to write code in C#. I have a class called\n",
            "\"CSharpCode\" which is a C# class. I have a class called \"CSharpCodeTest\" which\n",
            "is a C# class. I have a class called \"CSharpCodeTestTest\"\n",
            "\n",
            "----\n",
            "Params: {'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'repetition_penalty': 1.5}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: Today I learned how to write code in Python, and I was able to write it\n",
            "in Python.  In Python, I wrote a simple class with a method called “write_file”,\n",
            "which writes the file name to a file and returns the file size. The file\n",
            "\n",
            "----\n",
            "Params: {'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'repetition_penalty': 1.5}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: Today I learned how to write code in C#, for example if myFunction() is\n",
            "not a member function of a class of type std::function returns:     if\n",
            "(myFunction()) {         myFunction();\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from textwrap import fill\n",
        "models = [\n",
        "    \"distilgpt2\",\n",
        "    \"EleutherAI/gpt-neo-125M\",\n",
        "    \"facebook/opt-125m\",\n",
        "]\n",
        "\n",
        "param_sets = [\n",
        "    dict(temperature=0.3, top_p=0.9, top_k=50,  repetition_penalty=1.5),\n",
        "    dict(temperature=0.7, top_p=0.9, top_k=50, repetition_penalty=1.5),\n",
        "    dict(temperature=1.0, top_p=0.9, top_k=50, repetition_penalty=1.5),\n",
        "]\n",
        "def run_model(model_name, params, prompt, max_new_tokens):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    output = model.generate(**inputs,\n",
        "      max_new_tokens=max_new_tokens,\n",
        "      temperature=params[\"temperature\"],\n",
        "      top_k=params[\"top_k\"],\n",
        "      top_p=params[\"top_p\"],\n",
        "      repetition_penalty=params[\"repetition_penalty\"],\n",
        "      do_sample=True\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "prompt = \"Today I learned how to write code in\"\n",
        "model = models[1]\n",
        "print(f\"\\n\\nModel: {model}\")\n",
        "for p in param_sets:\n",
        "  print(f\"\\n----\\nParams: {p}\\n\")\n",
        "  output=f\"Output: {run_model(model, p, prompt,50)}\"\n",
        "  print(fill(output,width=80))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g61dnMX-Kqt8"
      }
    }
  ]
}